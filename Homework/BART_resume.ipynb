{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad29fc3-f259-4fd7-986c-b26b98a4713d",
   "metadata": {},
   "source": [
    "# Review of Article:  \"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension\"\n",
    "\n",
    "Link to article: https://arxiv.org/pdf/1910.13461"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e109dbf-804c-4540-bfd1-dd1a3a2db655",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "- Mike Lewis, \n",
    "- Yinhan Liu, \n",
    "- Naman Goyal, \n",
    "- Marjan Ghazvininejad, \n",
    "- Abdelrahman Mohamed, \n",
    "- Omer Levy, \n",
    "- Ves Stoyanov, \n",
    "- Luke Zettlemoyer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0f02f-caf0-4abd-9f3c-7d40080c7214",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "BART (Bidirectional Encoder Representations from Transformers) is a novel sequence-to-sequence model designed to tackle challenges in natural language processing tasks like generation, translation, and comprehension. It achieves this through a unique denoising pre-training approach. By reconstructing text corrupted with various noise functions (e.g., token masking, shuffling, deletion), BART learns robust representations that capture the underlying semantics of language.\n",
    "\n",
    "### Core Functionality:\n",
    "\n",
    "This denoising pre-training technique is central to BART's functionality. BART's training process involves corrupting the input sequence with various noise functions, such as token masking, random shuffling, and sentence deletion. During training, the model receives corrupted text and attempts to reconstruct the original sequence. This process forces BART to develop deep bidirectional representations that capture both the semantic meaning and syntactic structure of language.\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "BART adopts the standard transformer architecture but adjusts it for its unique objectives:\n",
    "- Encoder: Processes the corrupted input bidirectionally, capturing contextual information from the entire sequence.\n",
    "- Decoder: Autoregressively generates output, ensuring coherence and sequence fidelity.\n",
    "\n",
    "This design allows BART to perform well in both sequence-to-sequence tasks (e.g., summarization) and token-level tasks (e.g., classification).\n",
    "\n",
    "### Evaluation and Results:\n",
    "\n",
    "\n",
    "The authors tested BART across several NLP benchmarks and tasks, achieving state-of-the-art performance in many cases:\n",
    "\n",
    "- Text Summarization: Achieved leading results on CNN/DailyMail and XSum datasets.\n",
    "\n",
    "- Machine Translation: Demonstrated competitive performance without task-specific pretraining.\n",
    "\n",
    "- Question Answering: Performed well on the SQuAD dataset, showcasing its comprehension capabilities.\n",
    "\n",
    "- Text Generation: Produced high-quality outputs in generative tasks, rivaling GPT-like models.\n",
    "\n",
    "The experiments highlight BART’s versatility and efficacy, making it a powerful tool for diverse NLP applications.\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "BART's flexible architecture and robust pretraining make it suitable for a wide range of NLP tasks. It can be used for automatically generating concise summaries of lengthy texts, translating text between languages without the need for extensive fine-tuning, understanding context and generating accurate responses to queries, and enhancing chatbots and conversational AI systems.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "BART presents a novel approach to pre-training sequence-to-sequence models through denoising. This technique empowers BART to acquire robust language representations, leading to superior performance on various NLP tasks. The success of BART highlights the potential of denoising pre-training for advancing the field of natural language processing.\n",
    "\n",
    "### Code Availability\n",
    "\n",
    "The implementation of BART is accessible through the Hugging Face Transformers library, with detailed documentation and pre-trained models for fine-tuning:\n",
    "\n",
    "Official github repository: https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b76ebb-d7e0-4db3-ad15-df2fd07173c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5f85536de34ae0857c0e1068357425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ggeorgieva.HAEMIMONT\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ggeorgieva.HAEMIMONT\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873dc88d9be049b993c86127bdceec3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca399ee2d5ff4bc5b8bab20c5531d05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62724042dd14f7d8a900751117c235f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711364bc32be407492739057eda5163f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c36caedad84060a9f475307583be42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfacdc2-7473-4c96-ab01-66a6eb539c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart. In the end, it‘s not the years in your life that count. It’s the life\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "text = \"\"\"The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart. In the end, it‘s not the years in your life that count. It’s the life in your years.\"\"\"\n",
    "\n",
    "# Tokenization and generate\n",
    "inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], max_length=50, min_length=20, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Summary text\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f4b91-5181-4743-b39a-85a678cbf033",
   "metadata": {},
   "source": [
    "# Results from BART Model Execution\n",
    "\n",
    "### **Original Text**\n",
    "> The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart. In the end, it‘s not the years in your life that count. It’s the life in your years.\n",
    "\n",
    "### **Generated Summary**\n",
    "> The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart. In the end, it‘s not the years in your life that count. It’s the life\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison Table**\n",
    "\n",
    "| Original Text                                                                                     | Generated Summary                                                                 |\n",
    "|---------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|\n",
    "| The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart. In the end, it‘s not the years in your life that count. It’s the life in your years. | The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart. In the end, it‘s not the years in your life that count. It’s the life |\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
